{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join( 'Final_Project', 'Resources', 'FOMC20070131meeting.csv'))\n",
    "df['polarity'] = df['Meeting of the Federal Open Market Committee on January 30–31, 2007'].apply(lambda x : 1 if x == 'positive' else 0)\n",
    "class_names = ['negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### nltk and string transformations\n",
    "from nltk import tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import string\n",
    "\n",
    "### sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [a, meeting, of, the, federal, open, market, c...\n",
      "1    [mr, bernanke, chairman\\nmr, geithner, vice, c...\n",
      "2    [mr, fisher, ms, pianalto, and, messrs, plosse...\n",
      "3    [mr, lacker, and, ms, yellen, presidents, of, ...\n",
      "4    [mr, barron, first, vice, president, federal, ...\n",
      "Name: Meeting of the Federal Open Market Committee on January 30–31, 2007, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A meeting of the Federal Open Market Committee was held in the offices of the Board of Governors of the Federal Reserve System in Washington, D.C., on Tuesday, January 30, 2007, at 2:00 p.m., and continued on Wednesday, January 31, 2007, at 9:00 a.m.  Those present were the following:',\n",
       " 'Mr. Bernanke, Chairman\\nMr. Geithner, Vice Chairman Ms. Bies\\nMr. Hoenig Mr. Kohn Mr. Kroszner Ms. Minehan Mr. Mishkin Mr. Moskow Mr. Poole Mr. Warsh',\n",
       " 'Mr. Fisher, Ms. Pianalto, and Messrs. Plosser and Stern, Alternate Members of the Federal Open Market Committee',\n",
       " 'Mr. Lacker and Ms. Yellen, Presidents of the Federal Reserve Banks of Richmond and San Francisco, respectively',\n",
       " 'Mr. Barron, First Vice President, Federal Reserve Bank of Atlanta']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Define simple space tokenizer\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "tk = tokenize.simple.SpaceTokenizer()\n",
    "\n",
    "def simple_tokenizer(x):\n",
    "    x = x.translate(translator).strip().lower()\n",
    "    return tk.tokenize(x)\n",
    "\n",
    "### Quick look at what the tokenizer produces\n",
    "print(df['Meeting of the Federal Open Market Committee on January 30–31, 2007'].head().apply(lambda x : simple_tokenizer(x)))\n",
    "\n",
    "### Developing the corpus or list of sentences for processing later\n",
    "corpus = df['Meeting of the Federal Open Market Committee on January 30–31, 2007'].tolist()\n",
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector features :  ['', '01', '02', '03', '03—i', '04', '05', '06', '08', '09', '1', '10', '100', '11', '116', '119000', '11—', '12', '120', '12¾']\n",
      "Vector shape/size :  (4476, 5411)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=simple_tokenizer, stop_words='english')\n",
    "tf = vectorizer.fit(corpus)\n",
    "X = tf.transform(corpus)\n",
    "\n",
    "### Combining result of TFIDF with `target` columns\n",
    "full_df = pd.concat([pd.DataFrame(X.toarray()), df['polarity']], axis=1)\n",
    "print(\"Vector features : \", vectorizer.get_feature_names()[0:20])\n",
    "print(\"Vector shape/size : \",X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-836b2c345c3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtarget_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'polarity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m X_train, X_test, y_train, y_test = train_test_split(full_df.drop(target_col, axis=1)\n\u001b[1;32m----> 3\u001b[1;33m                                                   ,y,test_size=0.25, random_state=SEED)\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "target_col = 'polarity'\n",
    "X_train, X_test, y_train, y_test = train_test_split(full_df.drop(target_col, axis=1)\n",
    "                                                  ,y,test_size=0.25, random_state=SEED)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
